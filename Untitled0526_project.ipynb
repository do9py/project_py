{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0526-project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJig0FxxhsNdHwVziw99Qn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/do9py/project_py/blob/main/Untitled0526_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBqObH8S_5ts"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeTIEEx9B1vw"
      },
      "source": [
        "\t- 가나다라마 GAN Model - 삐뚤빼뚤 한글 이미지 생성\n",
        "\n",
        "Part1. 프로젝트 셋팅\n",
        "파트2. 데이터 준비\n",
        "파트3. 생성자 모델\n",
        "파트4. 판별자 모델\n",
        "파트5. 옵티마이저 + 로스 펑션\n",
        "파트6. GAN 모델 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vI4s6QRB7QM",
        "outputId": "50ebbaba-0390-45c3-c6bb-ed8c31f1fb44"
      },
      "source": [
        " \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as layers\n",
        " \n",
        "print(\"Tensorflow Version: %s\" % tf.__version__)\n",
        "print(\"Keras Version: %s\" % tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow Version: 2.5.0\n",
            "Keras Version: 2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrab9hN0B9qN",
        "outputId": "20495ac7-2eb8-4f70-8fb0-43e1db684b5c"
      },
      "source": [
        "from google.colab import drive\n",
        " \n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "rpG8b8mcCPPP",
        "outputId": "f00b4c92-806a-4e89-866e-4dffb1bdac04"
      },
      "source": [
        "# 2-1. CSV 데이터 읽어오기\n",
        "import pandas as pd\n",
        " \n",
        "data = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/image_pixels_augmented.csv').astype('float32')\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-491182cb46fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/Colab Notebooks/image_pixels_augmented.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/Colab Notebooks/image_pixels_augmented.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44rVjK4pATnc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qacb4qa-DEQk",
        "outputId": "cb7783fd-251b-4523-bdf9-a1da3e07796f"
      },
      "source": [
        "# 2-2. 30 Vector 변환\n",
        " \n",
        "width, height, channel = 32, 32, 1 #이미지 사이즈 32*32 pixel\n",
        " \n",
        "X = data.values\n",
        "X = X.reshape((X.shape[0], width, height, channel))\n",
        " \n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9962, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4IvmgKIEOuC",
        "outputId": "101e2ddd-4270-43a8-95a9-03a2a105576e"
      },
      "source": [
        "# 2-3. Image Pixel Normalization [0,255] -> [-1,1]\n",
        " \n",
        "X = (X - 127.5) / 127.5\n",
        " \n",
        "print(X[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1.        ]\n",
            "  [1.        ]\n",
            "  [1.        ]\n",
            "  ...\n",
            "  [1.        ]\n",
            "  [1.        ]\n",
            "  [1.        ]]\n",
            "\n",
            " [[1.        ]\n",
            "  [1.        ]\n",
            "  [1.        ]\n",
            "  ...\n",
            "  [1.        ]\n",
            "  [1.        ]\n",
            "  [1.        ]]\n",
            "\n",
            " [[1.        ]\n",
            "  [1.        ]\n",
            "  [1.        ]\n",
            "  ...\n",
            "  [1.        ]\n",
            "  [1.        ]\n",
            "  [1.        ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.99215686]\n",
            "  [0.9843137 ]\n",
            "  [0.99215686]\n",
            "  ...\n",
            "  [1.        ]\n",
            "  [1.        ]\n",
            "  [1.        ]]\n",
            "\n",
            " [[1.        ]\n",
            "  [1.        ]\n",
            "  [1.        ]\n",
            "  ...\n",
            "  [1.        ]\n",
            "  [1.        ]\n",
            "  [1.        ]]\n",
            "\n",
            " [[1.        ]\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  ...\n",
            "  [1.        ]\n",
            "  [1.        ]\n",
            "  [1.        ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "5uZ3OAZCEixf",
        "outputId": "4cf87e67-19e9-42e8-a653-df4712d4aab7"
      },
      "source": [
        "# 2-4. 한글 이미지 시각화\n",
        " \n",
        "plt.figure(figsize=(11,11))\n",
        " \n",
        "i = 1\n",
        "for image in X:\n",
        "  plt.subplot(10, 10, 1) #(!0*10) 총 100칸\n",
        "  image = image.reshape(width, height)\n",
        "  plt.imshow(image, cmap='gray') # 흑백 이미지\n",
        "  plt.axis('off')\n",
        "  i+=1\n",
        "  if i > 100: break\n",
        " \n",
        "plt.suptitle(\"Korean Image\", fontsize = 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 792x792 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkcB27pmFA58",
        "outputId": "7ff64729-f134-4be4-a947-8463357ec047"
      },
      "source": [
        "# 2-5. 학습 데이터 batch 준비\n",
        " \n",
        "BATCH_SIZE = 64\n",
        " \n",
        "# Input dataset + image random shuffle\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(X).shuffle(X.shape[0]).batch(BATCH_SIZE)\n",
        " \n",
        "print(train_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: (None, 32, 32, 1), types: tf.float32>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9TQ7fEmG7uH"
      },
      "source": [
        "파트3. 생성자 모델(Generator model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S7CGqtyHBkF"
      },
      "source": [
        "import tensorflow as tf\n",
        "# helps us to represent our data as lists easily and quickly\n",
        "import numpy as np\n",
        "# framework for defining a neural network as a set of Sequential layers\n",
        "from tensorflow import keras\n",
        " \n",
        " \n",
        "def build_generator_model():\n",
        "    model = tf.keras.Sequential() # Keras 모델 생성\n",
        "    \n",
        "    model.add(layers.Dense(1024, input_dim=100, use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    \n",
        "    model.add(layers.Dense(8*8*128, use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    \n",
        "    # Resahpe (8*8)\n",
        "    model.add(layers.Reshape((8, 8, 128)))  \n",
        "    \n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), \n",
        "                                    strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization()) \n",
        "    model.add(layers.LeakyReLU())\n",
        "    \n",
        "    # (8*8) -> (16*16)\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), \n",
        "                                    strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    \n",
        "    # (16*16) -> (32*32)\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), \n",
        "                                    strides=(2, 2), padding='same', activation='tanh'))\n",
        "    assert model.output_shape == (None, 32, 32, 1)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "fAenWnu3Hb9A",
        "outputId": "d0703ecf-b4ce-4d64-9dc3-393ffd87e183"
      },
      "source": [
        "#3-2. 생성자 모델 생성\n",
        "from tf.keras.layer import keras\n",
        " \n",
        "generator = build_generator_model()\n",
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-000b63b8ae5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#3-2. 생성자 모델 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_generator_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "vJT0mawIJd1n",
        "outputId": "1642a7f5-9076-4c83-dcb5-d0effcca0af7"
      },
      "source": [
        "#3-3. 학습도지 않은 생성자 모델이 만든 이미지\n",
        " \n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=false)\n",
        " \n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-1e0b68129879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2qie6e2KIEh"
      },
      "source": [
        "파트4. 판별자 모델 (Discri...Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUwuhQa5HOYo"
      },
      "source": [
        "# 4-1. Dis......모델 네트워크 구성\n",
        "\n",
        "def build_discriminator_model():\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=2, padding='same', \n",
        "                       input_shape=[32, 32, 1])) # input image size\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=2, padding='same'))\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "    \n",
        "    model.add(layers.Flatten())\n",
        "    \n",
        "    model.add(layers.Dense(256))\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Dense(1))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "y9aA79zoKUo9",
        "outputId": "fc6f4b33-d7a4-4b69-bbd2-85dd505d7ef9"
      },
      "source": [
        "#4-2. 판별자 모델 생성\n",
        "\n",
        "discriminator = build_discriminator_model\n",
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-95844ffd5757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_discriminator_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'summary'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GC3SUxOKtL8"
      },
      "source": [
        "#4-3. 학습되지 않은 판별자의 결과\n",
        "\n",
        "predicted = discriminator(generator_image)\n",
        "print(predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-WUZITxK3ge"
      },
      "source": [
        "파트5. 옵티마이저 + loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiK84zSoLAYc"
      },
      "source": [
        "#5-1. 옵티마이저 생성\n",
        "\n",
        "#생성자용\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "#판별자용\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1GqX5BiLZDf"
      },
      "source": [
        "#5-2. BinaryCrossentropy for minMax\n",
        "\n",
        "cross)entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK-zAAd4LpI9"
      },
      "source": [
        "#5-2. Generator Loss 함수\n",
        "\n",
        "#생성자 모델 목표: 판별자 모델이 가짜 이미지를 판별했을때 판별 값이 1에 가까워지도록\n",
        "def generator_loss(take_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output) # 1과 가짜 이미지를 판별 값 비교"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GczDjNgWMJHW"
      },
      "source": [
        "#5-3. Discri.... Loss 함수\n",
        "\n",
        "#판별자 모델 목표:\n",
        "#1. 진짜 이미지를 판별했을때 판별 값이 1에 가까워지도록\n",
        "#2. 가짜 이미지를 판별했을때 판별 값이 0에 가까워지도록\n",
        "def discriminator_loss(real_output, false_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output) #1. 1과 진짜 이미지 판별 값 비교\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output) #2. 0과 가짜 이미지 판별 값 비교\n",
        "  total_loss = real_loss + fake_loss\n",
        "  return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Glp4_LLlM_o_"
      },
      "source": [
        "파트6. GAN학습(G+D\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mSFjOv4NDaS"
      },
      "source": [
        "#6-1. 학습 값 설정\n",
        "\n",
        "EPOCHS = 300\n",
        "noise_dim = 100\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny01_7RJNaK8"
      },
      "source": [
        "@tf.function\n",
        "28:01영상"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}